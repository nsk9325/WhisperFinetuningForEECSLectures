{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1f54a5cd",
      "metadata": {
        "id": "1f54a5cd"
      },
      "source": [
        "# Whisper Small ë‹¤ë‹¨ê³„ íŒŒì¸íŠœë‹Â ë…¸íŠ¸ë¶\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì€ ì „ì²˜ë¦¬ëœ **MIT ì˜ì–´ê°•ì˜** ë°ì´í„°ì…‹ìœ¼ë¡œ OpenAI **Whisperâ€‘small** ëª¨ë¸ì„ ë‘ ë‹¨ê³„ë¡œ íŒŒì¸íŠœë‹í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43fadf00",
      "metadata": {
        "id": "43fadf00"
      },
      "source": [
        "## 1. í™˜ê²½ ì¤€ë¹„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d96c33ca",
      "metadata": {
        "id": "d96c33ca"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U \"transformers==4.52.3\" datasets accelerate evaluate jiwer\n",
        "!pip install -q git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cec45b6",
      "metadata": {
        "id": "1cec45b6"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "521f29f1",
      "metadata": {
        "id": "521f29f1"
      },
      "source": [
        "## 2. ë°ì´í„° ë¡œë“œ & ì•ˆì „í•œ ê²€ì¦ split ìƒì„±\n",
        "`validation` split ì´ ì—†ëŠ” ê²½ìš° ìë™ìœ¼ë¡œ `test` ë˜ëŠ” `train` 10â€¯%ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "383238ea",
      "metadata": {
        "id": "383238ea"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "def get_eval_split(dataset_dict, pct=0.1):\n",
        "    # validationì´ ì´ë¯¸ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ë¦¬í„´\n",
        "    if \"validation\" in dataset_dict:\n",
        "        return dataset_dict[\"validation\"]\n",
        "\n",
        "    # testê°€ ìˆìœ¼ë©´ testë¥¼ í‰ê°€ ë°ì´í„°ë¡œ ì‚¬ìš©\n",
        "    if \"test\" in dataset_dict:\n",
        "        return dataset_dict[\"test\"]\n",
        "\n",
        "    # ë‘˜ ë‹¤ ì—†ìœ¼ë©´ trainì„ pct ë¹„ìœ¨ë§Œí¼ ë–¼ì„œ validation(test)ìœ¼ë¡œ ì‚¬ìš©\n",
        "    print(f\"âš ï¸ 'validation' splitì´ ì—†ì–´ trainì˜ {int(pct*100)}%ë¥¼ evalë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
        "    split = dataset_dict[\"train\"].train_test_split(test_size=pct, seed=42)\n",
        "    dataset_dict[\"train\"] = split[\"train\"]\n",
        "    return split[\"test\"]\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "MIT = load_dataset(\"yongjune2002/MITOCW-Whisper-Processed\")\n",
        "\n",
        "# 1) eval_dsë¥¼ ë¨¼ì € ë§Œë“¤ì–´ì„œ MIT[\"train\"]ì´ 90%ë§Œ ë‚¨ë„ë¡ ìˆ˜ì •\n",
        "eval_ds = get_eval_split(MIT, pct=0.1)\n",
        "\n",
        "# 2) ì´ì œ MIT[\"train\"]ì—ëŠ” â€œë‚˜ë¨¸ì§€ 90%â€ë§Œ ë‚¨ì•˜ìœ¼ë¯€ë¡œ, ë°”ë¡œ trainìœ¼ë¡œ ì‚¬ìš©í•˜ë©´ ëœë‹¤\n",
        "train_ds = MIT[\"train\"]\n",
        "\n",
        "# (í•„ìš”í•˜ë‹¤ë©´ train_dsì—ë§Œ shuffle, map, tokenization ë“± ì „ì²˜ë¦¬ ì§„í–‰)\n",
        "print(train_ds)\n",
        "print(eval_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6c9a5be",
      "metadata": {
        "id": "a6c9a5be"
      },
      "source": [
        "## 3. ë°ì´í„° ì½œë ˆì´í„°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f430c25",
      "metadata": {
        "id": "4f430c25"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Union\n",
        "import torch\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorSpeechSeq2SeqWithPadding:\n",
        "    processor: any\n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]):\n",
        "        input_feats = [{\"input_features\": f[\"input_features\"]} for f in features]\n",
        "        label_feats = [{\"input_ids\": f[\"labels\"]} for f in features]\n",
        "        batch = self.processor.feature_extractor.pad(input_feats, return_tensors=\"pt\")\n",
        "        labels = self.processor.tokenizer.pad(label_feats, padding=True, return_tensors=\"pt\").input_ids\n",
        "        labels[labels == self.processor.tokenizer.pad_token_id] = -100\n",
        "        batch[\"labels\"] = labels\n",
        "        return batch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a28aefa7",
      "metadata": {
        "id": "a28aefa7"
      },
      "source": [
        "## 4. ëª¨ë¸ & í”„ë¡œì„¸ì„œ ë¡œë“œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6cfc473",
      "metadata": {
        "id": "f6cfc473"
      },
      "outputs": [],
      "source": [
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "\n",
        "checkpoint = \"openai/whisper-small\"\n",
        "processor = WhisperProcessor.from_pretrained(checkpoint)\n",
        "processor.tokenizer.set_prefix_tokens(language=\"en\", task=\"transcribe\")\n",
        "model = WhisperForConditionalGeneration.from_pretrained(checkpoint)\n",
        "\n",
        "# 1ë‹¨ê³„: ì¸ì½”ë” freeze\n",
        "for p in model.model.encoder.parameters():\n",
        "    p.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_ds)"
      ],
      "metadata": {
        "id": "Y5fa2_7-RA6x"
      },
      "id": "Y5fa2_7-RA6x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "8a62f573",
      "metadata": {
        "id": "8a62f573"
      },
      "source": [
        "## 5. ë‘ ë‹¨ê³„ í•™ìŠµ ì½œë°±"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "910ea525",
      "metadata": {
        "id": "910ea525"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainerCallback\n",
        "\n",
        "class UnfreezeBottom2Callback(TrainerCallback):\n",
        "    def on_step_end(self, args, state, control, **kwargs):\n",
        "        if state.global_step == 100:\n",
        "            print(\"â–¶ï¸  Unfreezing bottom 2 encoder layers â€¦\")\n",
        "            for layer in model.model.encoder.layers[:2]:\n",
        "                for p in layer.parameters():\n",
        "                    p.requires_grad = True"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b95664c",
      "metadata": {
        "id": "6b95664c"
      },
      "source": [
        "## 6. íŠ¸ë ˆì´ë‹ ì¸ì"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f865e18",
      "metadata": {
        "id": "2f865e18"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"whisper-mit\",\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=8,\n",
        "    learning_rate=5e-6,\n",
        "    warmup_steps=50,\n",
        "    num_train_epochs=10,\n",
        "    weight_decay=0.01,\n",
        "    fp16=False,\n",
        "\n",
        "    eval_strategy=\"epoch\",           # ì—í­ì´ ëë‚  ë•Œë§ˆë‹¤ í‰ê°€\n",
        "    save_strategy=\"epoch\",           # ì—í­ì´ ëë‚  ë•Œë§ˆë‹¤ ì €ì¥\n",
        "\n",
        "    save_total_limit=1,\n",
        "\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=50,\n",
        "\n",
        "    gradient_checkpointing=True,\n",
        "    predict_with_generate=True,\n",
        "\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"wer\",\n",
        "    greater_is_better=False,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2793f936",
      "metadata": {
        "id": "2793f936"
      },
      "source": [
        "## 7. í‰ê°€ í•¨ìˆ˜: WER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a517459",
      "metadata": {
        "id": "3a517459"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "wer_metric = evaluate.load(\"wer\")\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    pred_ids = pred.predictions\n",
        "    label_ids = pred.label_ids\n",
        "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n",
        "    return {\"wer\": wer_metric.compute(predictions=pred_str, references=label_str)}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a326ee83",
      "metadata": {
        "id": "a326ee83"
      },
      "source": [
        "## 8. Trainer ì´ˆê¸°í™”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40663c7c",
      "metadata": {
        "id": "40663c7c"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainer, EarlyStoppingCallback\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=eval_ds,\n",
        "    data_collator=DataCollatorSpeechSeq2SeqWithPadding(processor),\n",
        "    tokenizer=processor.tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[\n",
        "        UnfreezeBottom2Callback(),\n",
        "        EarlyStoppingCallback(early_stopping_patience=2)\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2eeb856",
      "metadata": {
        "id": "c2eeb856"
      },
      "source": [
        "## 9. í•™ìŠµ ì‹œì‘ ğŸš€"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f4b2785",
      "metadata": {
        "id": "8f4b2785"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e297ebb",
      "metadata": {
        "id": "9e297ebb"
      },
      "source": [
        "## 10. ëª¨ë¸ ì—…ë¡œë“œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11238fda",
      "metadata": {
        "id": "11238fda"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "login(token=\"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\")\n",
        "\n",
        "# 2) ëª¨ë¸ & í”„ë¡œì„¸ì„œ Push\n",
        "#    repo_nameì€ \"<username>/<repo_id>\" í˜•íƒœë¡œ ì§€ì •\n",
        "repo_name = \"tfbghjk/whisper-mit-small\"\n",
        "\n",
        "# ì´ë¯¸ ì •ì˜í•´ ë‘ì‹  Trainerì™€ Processor ê°ì²´ê°€ ìˆë‹¤ë©´\n",
        "trainer.push_to_hub(repo_name)\n",
        "processor.push_to_hub(repo_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model()                         # ./whisper-mit/pytorch_model.bin ë“± ìƒì„±\n",
        "processor.save_pretrained(\"./whisper-mit\")   # processor íŒŒì¼ë“¤(í† í¬ë‚˜ì´ì €) ìƒì„±"
      ],
      "metadata": {
        "id": "ka6fIQaws5Pz"
      },
      "id": "ka6fIQaws5Pz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "from huggingface_hub import login\n",
        "login(token=\"í—ˆê¹…í˜ì´ìŠ¤ í† í° ë„£ê¸°\")\n",
        "\n",
        "\n",
        "local_model_dir = \"./whisper-mit\"\n",
        "repo_name = \"tfbghjk/whisper-mit-small_v2\"\n",
        "\n",
        "processor = WhisperProcessor.from_pretrained(local_model_dir)\n",
        "processor.push_to_hub(repo_name)\n",
        "\n",
        "model = WhisperForConditionalGeneration.from_pretrained(local_model_dir)\n",
        "model.push_to_hub(repo_name)\n",
        "\n",
        "from transformers import Trainer\n",
        "trainer.push_to_hub(repo_name)"
      ],
      "metadata": {
        "id": "a8z2x5vhsWyv"
      },
      "id": "a8z2x5vhsWyv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "11ff3d5f",
      "metadata": {
        "id": "11ff3d5f"
      },
      "source": [
        "## 11. ê°„ë‹¨ í…ŒìŠ¤íŠ¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcd32bcf",
      "metadata": {
        "id": "bcd32bcf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "sample = eval_ds[0]\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ëª¨ë¸ì„ float32ë¡œ ê°•ì œ\n",
        "model = model.to(device).float()\n",
        "\n",
        "# inputë„ float32ë¡œ ê°•ì œ\n",
        "input_features = torch.tensor(sample['input_features']).unsqueeze(0).to(device).float()\n",
        "\n",
        "predicted_ids = model.generate(input_features)\n",
        "print(processor.decode(predicted_ids[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b928b20a",
      "metadata": {
        "id": "b928b20a"
      },
      "source": [
        "**12. (ì„ íƒ) Gradio ë°ëª¨**##"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "a6DKxdA0cT7p"
      },
      "id": "a6DKxdA0cT7p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**13. Evaluation**\n"
      ],
      "metadata": {
        "id": "UGhzFv1-t56m"
      },
      "id": "UGhzFv1-t56m"
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate after training\n",
        "results = trainer.evaluate()\n",
        "\n",
        "# Print the results (WER and other metrics)\n",
        "print(\"Evaluation results:\", results)"
      ],
      "metadata": {
        "id": "HmTcdgZguAFx"
      },
      "id": "HmTcdgZguAFx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparing"
      ],
      "metadata": {
        "id": "Mjpr1xCJuWRy"
      },
      "id": "Mjpr1xCJuWRy"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import WhisperForConditionalGeneration\n",
        "\n",
        "# 1ï¸âƒ£ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ í‰ê°€\n",
        "pretrained_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\").to(device).float()\n",
        "trainer.model = pretrained_model  # Trainerì— ëª¨ë¸ í• ë‹¹\n",
        "pretrained_results = trainer.evaluate()\n",
        "print(\"Pretrained model WER:\", pretrained_results[\"eval_wer\"])\n",
        "\n",
        "# 2ï¸âƒ£ íŒŒì¸íŠœë‹ëœ ëª¨ë¸ í‰ê°€\n",
        "trainer.model = model  # fine-tuned modelë¡œ êµì²´\n",
        "fine_tuned_results = trainer.evaluate()\n",
        "print(\"Fine-tuned model WER:\", fine_tuned_results[\"eval_wer\"])\n",
        "\n",
        "# 3ï¸âƒ£ ì„±ëŠ¥ ë¹„êµ\n",
        "improvement_in_wer = pretrained_results['eval_wer'] - fine_tuned_results['eval_wer']\n",
        "print(f\"WER improvement after fine-tuning: {improvement_in_wer:.4f}\")"
      ],
      "metadata": {
        "id": "BocJE2LpuYJn"
      },
      "id": "BocJE2LpuYJn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "import gradio as gr\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "\n",
        "# Hugging Faceì—ì„œ pretrained whisper-small ë¡œë“œ\n",
        "checkpoint = \"openai/whisper-small\"\n",
        "processor = WhisperProcessor.from_pretrained(checkpoint)\n",
        "model = WhisperForConditionalGeneration.from_pretrained(checkpoint).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def transcribe(file):\n",
        "    # íŒŒì¼ì—ì„œ waveform ë¡œë“œ\n",
        "    speech_array, sampling_rate = torchaudio.load(file)\n",
        "\n",
        "    # WhisperëŠ” 16kHz ìƒ˜í”Œë§ ê¸°ëŒ€ â†’ í•„ìš”ì‹œ ë¦¬ìƒ˜í”Œë§\n",
        "    if sampling_rate != 16000:\n",
        "        resampler = torchaudio.transforms.Resample(orig_freq=sampling_rate, new_freq=16000)\n",
        "        speech_array = resampler(speech_array)\n",
        "\n",
        "    # Whisper feature ì¶”ì¶œ\n",
        "    input_features = processor.feature_extractor(\n",
        "        speech_array.squeeze().numpy(), sampling_rate=16000, return_tensors=\"pt\"\n",
        "    ).input_features.to(model.device)\n",
        "\n",
        "    # Whisper ëª¨ë¸ë¡œ ì˜ˆì¸¡\n",
        "    predicted_ids = model.generate(input_features)\n",
        "    transcription = processor.decode(predicted_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return transcription\n",
        "\n",
        "# Gradio ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰\n",
        "gr.Interface(fn=transcribe, inputs=gr.Audio(type=\"filepath\"), outputs=\"text\").launch()\n"
      ],
      "metadata": {
        "id": "6SwGQlyEksHE"
      },
      "id": "6SwGQlyEksHE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "import gradio as gr\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "\n",
        "checkpoint = \"tfbghjk/whisper-mit-small_v2\"\n",
        "\n",
        "# 1) Processor(í† í¬ë‚˜ì´ì € + feature-extractor) ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "processor = WhisperProcessor.from_pretrained(checkpoint)\n",
        "processor.tokenizer.set_prefix_tokens(language=\"en\", task=\"transcribe\")\n",
        "\n",
        "# 2) ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° (GPU/CPU í• ë‹¹)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = WhisperForConditionalGeneration.from_pretrained(checkpoint).to(device)\n",
        "\n",
        "model.generation_config.forced_decoder_ids = None\n",
        "model.config.forced_decoder_ids = None\n",
        "\n",
        "\n",
        "def transcribe(file):\n",
        "    speech_array, sampling_rate = torchaudio.load(file)\n",
        "    if sampling_rate != 16000:\n",
        "        resampler = torchaudio.transforms.Resample(orig_freq=sampling_rate, new_freq=16000)\n",
        "        speech_array = resampler(speech_array)\n",
        "\n",
        "    input_features = processor.feature_extractor(\n",
        "        speech_array.squeeze().numpy(),\n",
        "        sampling_rate=16000,\n",
        "        return_tensors=\"pt\"\n",
        "    ).input_features.to(device)\n",
        "\n",
        "    predicted_ids = model.generate(input_features)\n",
        "\n",
        "    transcription = processor.decode(predicted_ids[0], skip_special_tokens=True)\n",
        "    return transcription\n",
        "\n",
        "\n",
        "# 6) Gradio ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰\n",
        "gr.Interface(\n",
        "    fn=transcribe,\n",
        "    inputs=gr.Audio(type=\"filepath\"),\n",
        "    outputs=\"text\"\n",
        ").launch()\n"
      ],
      "metadata": {
        "id": "wb-BoX7U1kx5"
      },
      "id": "wb-BoX7U1kx5",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}